# Отчет по домашнему заданию №3: DWH и загрузка данных в целевую систему

## Цель задания

Научиться загружать данные, используя Apache Airflow, настроив два процесса: один для полной загрузки исторических данных и второй для инкрементальной загрузки изменений за последние несколько дней.

## Используемые инструменты

  * Apache Airflow (версия, если известна, например, 2.x.x)
  * Python (версия, если известна, например, 3.x)
  * Библиотека `pandas` для обработки данных

## Описание выполнения задания

В рамках данного домашнего задания были разработаны два процесса (DAGа) в Apache Airflow для загрузки преобразованных данных. В качестве исходных данных использовался CSV-файл `transformed_weather.csv`, являющийся результатом предыдущих этапов обработки данных.

В качестве "целевой системы" для упрощения была выбрана файловая система. Результаты полной и инкрементальной загрузок сохраняются в виде новых CSV-файлов в директорию `/opt/airflow/dags/output_dwh/` внутри окружения Airflow.

### 1\. Процесс полной загрузки данных

  * **DAG ID:** `Lebedeva_Marina_DZ_3_FullLoad`
  * **Описание:** Данный DAG считывает все данные из исходного файла `transformed_weather.csv`.
  * **Результат:** Все считанные данные сохраняются в единый файл `transformed_weather_full_load.csv` в директории `/opt/airflow/dags/output_dwh/`. При каждом запуске DAGа этот файл перезаписывается.
  * **Расписание:** `@once`, предназначен для однократного или ручного запуска.

### 2\. Процесс инкрементальной загрузки данных

  * **DAG ID:** `Lebedeva_Marina_DZ_3_IncrementalLoad`
  * **Описание:** Данный DAG также считывает данные из исходного файла `transformed_weather.csv`. Затем он фильтрует эти данные, оставляя только записи, относящиеся к "последним нескольким дням" (в реализации использовалось окно в 3 дня) относительно логической даты выполнения DAG (`execution_date`, передаваемой через макрос `{{ ds }}`).
  * **Результат:** Отфильтрованные (инкрементальные) данные сохраняются в новый CSV-файл, имя которого включает дату выполнения. Например, `transformed_weather_incremental_20231028.csv` (для даты `2023-10-28`) в директории `/opt/airflow/dags/output_dwh/`.
  * **Расписание:** `@daily` (или другой настроенный интервал) для регулярного подхватывания изменений.

## Реализация в Apache Airflow

Оба процесса были реализованы как отдельные DAGи в Apache Airflow с использованием TaskFlow API (декораторы `@dag` и `@task`).

  * **DAG полной загрузки** состоит из двух основных задач:
    1.  Чтение данных из исходного CSV-файла (`read_source_data`).
    2.  Запись полного набора данных в целевой CSV-файл (`write_full_load_to_csv`).
  * **DAG инкрементальной загрузки** состоит из трех основных задач:
    1.  Чтение данных из исходного CSV-файла (`read_source_data_for_increment`).
    2.  Фильтрация данных для получения записей за последние N дней (`filter_recent_data_for_increment`).
    3.  Запись отфильтрованных (инкрементальных) данных в новый CSV-файл с датой в имени (`write_incremental_data_to_csv`).

Оба DAGа были успешно протестированы и выполнены в среде Apache Airflow, что подтверждается приложенным скриншотом веб-интерфейса.

## Результаты выполнения

  * После успешного запуска DAGа полной загрузки в директории `/opt/airflow/dags/output_dwh/` создается (или перезаписывается) файл `transformed_weather_full_load.csv`.
  * После каждого успешного запуска DAGа инкрементальной загрузки в директории `/opt/airflow/dags/output_dwh/` создается новый файл с инкрементальными данными, например, `transformed_weather_incremental_YYYYMMDD.csv`.