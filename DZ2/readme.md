# Отчет по домашнему заданию №2

### Цель задания

Практика чтения сложных форматов данных (JSON, XML) и выполнения преобразований данных с использованием инструмента Apache Airflow.

### Используемые инструменты

Для выполнения задания использовались:
* Apache Airflow (развернут с помощью Docker Compose)
* Python с библиотеками `pandas`, `json`, `xml.etree.ElementTree`, `requests`.

### Выполнение Задания 1: Приведение сложных форматов к линейной структуре

В рамках данного задания выполнена разработка задач Airflow DAG для чтения данных из файлов JSON и XML и приведения их к плоской (линейной) структуре.

**Обработка JSON:**
Использован файл `pets-data.json`. Данные, представляющие список питомцев с вложенными структурами (список любимых блюд), были прочитаны. Список любимых блюд (`favFoods`) для каждого питомца преобразован в строку, объединенную запятыми. Результат обработки выведен в логи задачи Airflow, а также сохранен в файл `flattened_pets.csv` в папке с данными (`/opt/airflow/dags/data/`).

![Скриншот логов обработки JSON](logs_process_json_data.png)

**Обработка XML:**
Использован файл `nutrition.xml`. Данные, содержащие информацию о продуктах питания с вложенными элементами и атрибутами (например, `<calories>`, `<serving>`, `<vitamins>`, `<minerals>`), были прочитаны. Данные из вложенных структур извлечены и представлены на верхнем уровне для каждого продукта. Результат обработки выведен в логи задачи Airflow, а также сохранен в файл `flattened_nutrition.csv` в папке с данными (`/opt/airflow/dags/data/`).

![Скриншот логов обработки XML](logs_process_xml_data.png)

---

### Выполнение Задания 2: Преобразование данных датасета

Для выполнения данного задания использован датасет из файла `IOT-temp.csv`. Разработаны задачи Airflow DAG для выполнения следующих преобразований:

1.  **Вычисление самых жарких и холодных дней за осень:**
    Данные из датасета были отфильтрованы по осенним месяцам (сентябрь, октябрь, ноябрь). Среди этих данных найдены 5 дней с самыми высокими и 5 дней с самыми низкими температурами. Результаты (даты и соответствующие температуры) выведены в логи задачи `analyze_weather_data`.

    ![Скриншот логов анализа погоды](logs_analyze_weather_data.png)

2.  **Фильтрация данных:**
    Из всего датасета оставлены только строки, где значение в колонке `out/in` равно `'in'`. При выполнении учтены возможные пробелы и регистр символов в исходных данных для корректной фильтрации.

3.  **Форматирование даты:**
    Значения в колонке `noted_date` преобразованы в формат `ГГГГ-ММ-ДД` (`yyyy-MM-dd`).

4.  **Очистка температуры по процентилям:**
    Для данных, оставшихся после фильтрации, рассчитаны 5-й и 95-й процентили температуры. Строки со значениями температуры ниже 5-го процентиля или выше 95-го процентиля были удалены.

Результат всех преобразований сохранен в новый файл `transformed_weather.csv` в папке с данными (`/opt/airflow/dags/data/`).

---

### Реализация в Apache Airflow

Все шаги задания реализованы в виде задач (`@task`) в одном DAG (`@dag`) Apache Airflow. DAG определен в файле `Lebedeva_Marina_DZ_2.py`. Задачи обработки данных погоды (`analyze_weather_data` и `transform_weather_data`) связаны последовательно. Задачи обработки JSON (`process_json_data`) и XML (`process_xml_data`) выполняются независимо и предшествуют задачам обработки данных погоды.

DAG успешно запущен в веб-интерфейсе Airflow.

![Скриншот успешного выполнения DAG Lebedeva_Marina_DZ_2 в Airflow](Lebedeva_Marina_DZ_2-Grid-Airflow.png)

---

### Результаты выполнения

После успешного запуска DAG:
* В логах задачи `analyze_weather_data` содержится список 5 самых жарких и холодных осенних дней (см. скриншот `logs_analyze_weather_data.png`).
* В логах задачи `process_json_data` отображен процесс обработки JSON файла (см. скриншот `logs_process_json_data.png`).
* В логах задачи `process_xml_data` отображен процесс обработки XML файла (см. скриншот `logs_process_xml_data.png`).
* В папке `/opt/airflow/dags/data/` создан файл `transformed_weather.csv`, содержащий данные после фильтрации по `out/in`, форматирования даты и очистки температуры.
* В папке `/opt/airflow/dags/data/` создан файл `flattened_pets.csv` с выравненными данными из JSON.
* В папке `/opt/airflow/dags/data/` создан файл `flattened_nutrition.csv` с выравненными данными из XML.

---

### Правила приёма работы и Чек-лист самопроверки

Для сдачи домашнего задания подготовлены следующие материалы:

* Файл DAG: `Lebedeva_Marina_DZ_2.py`. Название файла соответствует требованиям (Фамилия_Имя_ДЗ_Номер).
* Скриншот веб-интерфейса Apache Airflow, демонстрирующий успешное выполнение DAG `Lebedeva_Marina_DZ_2` (файл `Lebedeva_Marina_DZ_2-Grid-Airflow.png`).
* Скриншоты логов выполнения ключевых задач:
    * `logs_process_json_data.png`
    * `logs_process_xml_data.png`
    * `logs_analyze_weather_data.png`
* Выходные файлы (лежат в папке data проекта):
    * `transformed_weather.csv`
    * `flattened_pets.csv`
    * `flattened_nutrition.csv`